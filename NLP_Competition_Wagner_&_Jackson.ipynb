{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Competition - Wagner & Jackson.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zn4zebm4n-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importações das bibliotecas\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-t8aaOJ4n-o",
        "colab_type": "code",
        "outputId": "613be36d-a777-44b9-e1d8-b43526c63a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#carrega as stopwords pt-BR\n",
        "stopwords = pd.read_csv('https://raw.githubusercontent.com/stopwords-iso/stopwords-pt/master/stopwords-pt.txt', header=None)[0].values.tolist()\n",
        "stopwords"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'acerca',\n",
              " 'adeus',\n",
              " 'agora',\n",
              " 'ainda',\n",
              " 'alem',\n",
              " 'algmas',\n",
              " 'algo',\n",
              " 'algumas',\n",
              " 'alguns',\n",
              " 'ali',\n",
              " 'além',\n",
              " 'ambas',\n",
              " 'ambos',\n",
              " 'ano',\n",
              " 'anos',\n",
              " 'antes',\n",
              " 'ao',\n",
              " 'aonde',\n",
              " 'aos',\n",
              " 'apenas',\n",
              " 'apoio',\n",
              " 'apontar',\n",
              " 'apos',\n",
              " 'após',\n",
              " 'aquela',\n",
              " 'aquelas',\n",
              " 'aquele',\n",
              " 'aqueles',\n",
              " 'aqui',\n",
              " 'aquilo',\n",
              " 'as',\n",
              " 'assim',\n",
              " 'através',\n",
              " 'atrás',\n",
              " 'até',\n",
              " 'aí',\n",
              " 'baixo',\n",
              " 'bastante',\n",
              " 'bem',\n",
              " 'boa',\n",
              " 'boas',\n",
              " 'bom',\n",
              " 'bons',\n",
              " 'breve',\n",
              " 'cada',\n",
              " 'caminho',\n",
              " 'catorze',\n",
              " 'cedo',\n",
              " 'cento',\n",
              " 'certamente',\n",
              " 'certeza',\n",
              " 'cima',\n",
              " 'cinco',\n",
              " 'coisa',\n",
              " 'com',\n",
              " 'como',\n",
              " 'comprido',\n",
              " 'conhecido',\n",
              " 'conselho',\n",
              " 'contra',\n",
              " 'contudo',\n",
              " 'corrente',\n",
              " 'cuja',\n",
              " 'cujas',\n",
              " 'cujo',\n",
              " 'cujos',\n",
              " 'custa',\n",
              " 'cá',\n",
              " 'da',\n",
              " 'daquela',\n",
              " 'daquelas',\n",
              " 'daquele',\n",
              " 'daqueles',\n",
              " 'dar',\n",
              " 'das',\n",
              " 'de',\n",
              " 'debaixo',\n",
              " 'dela',\n",
              " 'delas',\n",
              " 'dele',\n",
              " 'deles',\n",
              " 'demais',\n",
              " 'dentro',\n",
              " 'depois',\n",
              " 'desde',\n",
              " 'desligado',\n",
              " 'dessa',\n",
              " 'dessas',\n",
              " 'desse',\n",
              " 'desses',\n",
              " 'desta',\n",
              " 'destas',\n",
              " 'deste',\n",
              " 'destes',\n",
              " 'deve',\n",
              " 'devem',\n",
              " 'deverá',\n",
              " 'dez',\n",
              " 'dezanove',\n",
              " 'dezasseis',\n",
              " 'dezassete',\n",
              " 'dezoito',\n",
              " 'dia',\n",
              " 'diante',\n",
              " 'direita',\n",
              " 'dispoe',\n",
              " 'dispoem',\n",
              " 'diversa',\n",
              " 'diversas',\n",
              " 'diversos',\n",
              " 'diz',\n",
              " 'dizem',\n",
              " 'dizer',\n",
              " 'do',\n",
              " 'dois',\n",
              " 'dos',\n",
              " 'doze',\n",
              " 'duas',\n",
              " 'durante',\n",
              " 'dá',\n",
              " 'dão',\n",
              " 'dúvida',\n",
              " 'e',\n",
              " 'ela',\n",
              " 'elas',\n",
              " 'ele',\n",
              " 'eles',\n",
              " 'em',\n",
              " 'embora',\n",
              " 'enquanto',\n",
              " 'entao',\n",
              " 'entre',\n",
              " 'então',\n",
              " 'era',\n",
              " 'eram',\n",
              " 'essa',\n",
              " 'essas',\n",
              " 'esse',\n",
              " 'esses',\n",
              " 'esta',\n",
              " 'estado',\n",
              " 'estamos',\n",
              " 'estar',\n",
              " 'estará',\n",
              " 'estas',\n",
              " 'estava',\n",
              " 'estavam',\n",
              " 'este',\n",
              " 'esteja',\n",
              " 'estejam',\n",
              " 'estejamos',\n",
              " 'estes',\n",
              " 'esteve',\n",
              " 'estive',\n",
              " 'estivemos',\n",
              " 'estiver',\n",
              " 'estivera',\n",
              " 'estiveram',\n",
              " 'estiverem',\n",
              " 'estivermos',\n",
              " 'estivesse',\n",
              " 'estivessem',\n",
              " 'estiveste',\n",
              " 'estivestes',\n",
              " 'estivéramos',\n",
              " 'estivéssemos',\n",
              " 'estou',\n",
              " 'está',\n",
              " 'estás',\n",
              " 'estávamos',\n",
              " 'estão',\n",
              " 'eu',\n",
              " 'exemplo',\n",
              " 'falta',\n",
              " 'fará',\n",
              " 'favor',\n",
              " 'faz',\n",
              " 'fazeis',\n",
              " 'fazem',\n",
              " 'fazemos',\n",
              " 'fazer',\n",
              " 'fazes',\n",
              " 'fazia',\n",
              " 'faço',\n",
              " 'fez',\n",
              " 'fim',\n",
              " 'final',\n",
              " 'foi',\n",
              " 'fomos',\n",
              " 'for',\n",
              " 'fora',\n",
              " 'foram',\n",
              " 'forem',\n",
              " 'forma',\n",
              " 'formos',\n",
              " 'fosse',\n",
              " 'fossem',\n",
              " 'foste',\n",
              " 'fostes',\n",
              " 'fui',\n",
              " 'fôramos',\n",
              " 'fôssemos',\n",
              " 'geral',\n",
              " 'grande',\n",
              " 'grandes',\n",
              " 'grupo',\n",
              " 'ha',\n",
              " 'haja',\n",
              " 'hajam',\n",
              " 'hajamos',\n",
              " 'havemos',\n",
              " 'havia',\n",
              " 'hei',\n",
              " 'hoje',\n",
              " 'hora',\n",
              " 'horas',\n",
              " 'houve',\n",
              " 'houvemos',\n",
              " 'houver',\n",
              " 'houvera',\n",
              " 'houveram',\n",
              " 'houverei',\n",
              " 'houverem',\n",
              " 'houveremos',\n",
              " 'houveria',\n",
              " 'houveriam',\n",
              " 'houvermos',\n",
              " 'houverá',\n",
              " 'houverão',\n",
              " 'houveríamos',\n",
              " 'houvesse',\n",
              " 'houvessem',\n",
              " 'houvéramos',\n",
              " 'houvéssemos',\n",
              " 'há',\n",
              " 'hão',\n",
              " 'iniciar',\n",
              " 'inicio',\n",
              " 'ir',\n",
              " 'irá',\n",
              " 'isso',\n",
              " 'ista',\n",
              " 'iste',\n",
              " 'isto',\n",
              " 'já',\n",
              " 'lado',\n",
              " 'lhe',\n",
              " 'lhes',\n",
              " 'ligado',\n",
              " 'local',\n",
              " 'logo',\n",
              " 'longe',\n",
              " 'lugar',\n",
              " 'lá',\n",
              " 'maior',\n",
              " 'maioria',\n",
              " 'maiorias',\n",
              " 'mais',\n",
              " 'mal',\n",
              " 'mas',\n",
              " 'me',\n",
              " 'mediante',\n",
              " 'meio',\n",
              " 'menor',\n",
              " 'menos',\n",
              " 'meses',\n",
              " 'mesma',\n",
              " 'mesmas',\n",
              " 'mesmo',\n",
              " 'mesmos',\n",
              " 'meu',\n",
              " 'meus',\n",
              " 'mil',\n",
              " 'minha',\n",
              " 'minhas',\n",
              " 'momento',\n",
              " 'muito',\n",
              " 'muitos',\n",
              " 'máximo',\n",
              " 'mês',\n",
              " 'na',\n",
              " 'nada',\n",
              " 'nao',\n",
              " 'naquela',\n",
              " 'naquelas',\n",
              " 'naquele',\n",
              " 'naqueles',\n",
              " 'nas',\n",
              " 'nem',\n",
              " 'nenhuma',\n",
              " 'nessa',\n",
              " 'nessas',\n",
              " 'nesse',\n",
              " 'nesses',\n",
              " 'nesta',\n",
              " 'nestas',\n",
              " 'neste',\n",
              " 'nestes',\n",
              " 'no',\n",
              " 'noite',\n",
              " 'nome',\n",
              " 'nos',\n",
              " 'nossa',\n",
              " 'nossas',\n",
              " 'nosso',\n",
              " 'nossos',\n",
              " 'nova',\n",
              " 'novas',\n",
              " 'nove',\n",
              " 'novo',\n",
              " 'novos',\n",
              " 'num',\n",
              " 'numa',\n",
              " 'numas',\n",
              " 'nunca',\n",
              " 'nuns',\n",
              " 'não',\n",
              " 'nível',\n",
              " 'nós',\n",
              " 'número',\n",
              " 'o',\n",
              " 'obra',\n",
              " 'obrigada',\n",
              " 'obrigado',\n",
              " 'oitava',\n",
              " 'oitavo',\n",
              " 'oito',\n",
              " 'onde',\n",
              " 'ontem',\n",
              " 'onze',\n",
              " 'os',\n",
              " 'ou',\n",
              " 'outra',\n",
              " 'outras',\n",
              " 'outro',\n",
              " 'outros',\n",
              " 'para',\n",
              " 'parece',\n",
              " 'parte',\n",
              " 'partir',\n",
              " 'paucas',\n",
              " 'pegar',\n",
              " 'pela',\n",
              " 'pelas',\n",
              " 'pelo',\n",
              " 'pelos',\n",
              " 'perante',\n",
              " 'perto',\n",
              " 'pessoas',\n",
              " 'pode',\n",
              " 'podem',\n",
              " 'poder',\n",
              " 'poderá',\n",
              " 'podia',\n",
              " 'pois',\n",
              " 'ponto',\n",
              " 'pontos',\n",
              " 'por',\n",
              " 'porque',\n",
              " 'porquê',\n",
              " 'portanto',\n",
              " 'posição',\n",
              " 'possivelmente',\n",
              " 'posso',\n",
              " 'possível',\n",
              " 'pouca',\n",
              " 'pouco',\n",
              " 'poucos',\n",
              " 'povo',\n",
              " 'primeira',\n",
              " 'primeiras',\n",
              " 'primeiro',\n",
              " 'primeiros',\n",
              " 'promeiro',\n",
              " 'propios',\n",
              " 'proprio',\n",
              " 'própria',\n",
              " 'próprias',\n",
              " 'próprio',\n",
              " 'próprios',\n",
              " 'próxima',\n",
              " 'próximas',\n",
              " 'próximo',\n",
              " 'próximos',\n",
              " 'puderam',\n",
              " 'pôde',\n",
              " 'põe',\n",
              " 'põem',\n",
              " 'quais',\n",
              " 'qual',\n",
              " 'qualquer',\n",
              " 'quando',\n",
              " 'quanto',\n",
              " 'quarta',\n",
              " 'quarto',\n",
              " 'quatro',\n",
              " 'que',\n",
              " 'quem',\n",
              " 'quer',\n",
              " 'quereis',\n",
              " 'querem',\n",
              " 'queremas',\n",
              " 'queres',\n",
              " 'quero',\n",
              " 'questão',\n",
              " 'quieto',\n",
              " 'quinta',\n",
              " 'quinto',\n",
              " 'quinze',\n",
              " 'quáis',\n",
              " 'quê',\n",
              " 'relação',\n",
              " 'sabe',\n",
              " 'sabem',\n",
              " 'saber',\n",
              " 'se',\n",
              " 'segunda',\n",
              " 'segundo',\n",
              " 'sei',\n",
              " 'seis',\n",
              " 'seja',\n",
              " 'sejam',\n",
              " 'sejamos',\n",
              " 'sem',\n",
              " 'sempre',\n",
              " 'sendo',\n",
              " 'ser',\n",
              " 'serei',\n",
              " 'seremos',\n",
              " 'seria',\n",
              " 'seriam',\n",
              " 'será',\n",
              " 'serão',\n",
              " 'seríamos',\n",
              " 'sete',\n",
              " 'seu',\n",
              " 'seus',\n",
              " 'sexta',\n",
              " 'sexto',\n",
              " 'sim',\n",
              " 'sistema',\n",
              " 'sob',\n",
              " 'sobre',\n",
              " 'sois',\n",
              " 'somente',\n",
              " 'somos',\n",
              " 'sou',\n",
              " 'sua',\n",
              " 'suas',\n",
              " 'são',\n",
              " 'sétima',\n",
              " 'sétimo',\n",
              " 'só',\n",
              " 'tal',\n",
              " 'talvez',\n",
              " 'tambem',\n",
              " 'também',\n",
              " 'tanta',\n",
              " 'tantas',\n",
              " 'tanto',\n",
              " 'tarde',\n",
              " 'te',\n",
              " 'tem',\n",
              " 'temos',\n",
              " 'tempo',\n",
              " 'tendes',\n",
              " 'tenha',\n",
              " 'tenham',\n",
              " 'tenhamos',\n",
              " 'tenho',\n",
              " 'tens',\n",
              " 'tentar',\n",
              " 'tentaram',\n",
              " 'tente',\n",
              " 'tentei',\n",
              " 'ter',\n",
              " 'terceira',\n",
              " 'terceiro',\n",
              " 'terei',\n",
              " 'teremos',\n",
              " 'teria',\n",
              " 'teriam',\n",
              " 'terá',\n",
              " 'terão',\n",
              " 'teríamos',\n",
              " 'teu',\n",
              " 'teus',\n",
              " 'teve',\n",
              " 'tinha',\n",
              " 'tinham',\n",
              " 'tipo',\n",
              " 'tive',\n",
              " 'tivemos',\n",
              " 'tiver',\n",
              " 'tivera',\n",
              " 'tiveram',\n",
              " 'tiverem',\n",
              " 'tivermos',\n",
              " 'tivesse',\n",
              " 'tivessem',\n",
              " 'tiveste',\n",
              " 'tivestes',\n",
              " 'tivéramos',\n",
              " 'tivéssemos',\n",
              " 'toda',\n",
              " 'todas',\n",
              " 'todo',\n",
              " 'todos',\n",
              " 'trabalhar',\n",
              " 'trabalho',\n",
              " 'treze',\n",
              " 'três',\n",
              " 'tu',\n",
              " 'tua',\n",
              " 'tuas',\n",
              " 'tudo',\n",
              " 'tão',\n",
              " 'tém',\n",
              " 'têm',\n",
              " 'tínhamos',\n",
              " 'um',\n",
              " 'uma',\n",
              " 'umas',\n",
              " 'uns',\n",
              " 'usa',\n",
              " 'usar',\n",
              " 'vai',\n",
              " 'vais',\n",
              " 'valor',\n",
              " 'veja',\n",
              " 'vem',\n",
              " 'vens',\n",
              " 'ver',\n",
              " 'verdade',\n",
              " 'verdadeiro',\n",
              " 'vez',\n",
              " 'vezes',\n",
              " 'viagem',\n",
              " 'vindo',\n",
              " 'vinte',\n",
              " 'você',\n",
              " 'vocês',\n",
              " 'vos',\n",
              " 'vossa',\n",
              " 'vossas',\n",
              " 'vosso',\n",
              " 'vossos',\n",
              " 'vários',\n",
              " 'vão',\n",
              " 'vêm',\n",
              " 'vós',\n",
              " 'zero',\n",
              " 'à',\n",
              " 'às',\n",
              " 'área',\n",
              " 'é',\n",
              " 'éramos',\n",
              " 'és',\n",
              " 'último']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUjOIhco4n-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concatena o título com o texto\n",
        "def append_title_text(row):\n",
        "    connector = '. ' if not row['title'].endswith('.') else ' '\n",
        "    return row['title'].strip() + connector + row['text'].strip()\n",
        "\n",
        "#carrega o arquivo de dataset  \n",
        "def load_dataset(filename, train=True):\n",
        "    raw_df = pd.read_csv(filename)\n",
        "    raw_df['text'] = raw_df.apply(lambda row: append_title_text(row), axis=1)\n",
        "    del raw_df['title']\n",
        "    if train:\n",
        "        raw_df = raw_df.rename(columns={'category': 'label'})\n",
        "    else:\n",
        "        del raw_df['id']\n",
        "    return raw_df\n",
        "\n",
        "#salva o arquivo de submissão\n",
        "def write_predictions(predictions, out_path):\n",
        "    count = 0\n",
        "    with open(out_path, mode='w', encoding='utf-8') as out_file:\n",
        "        print('Saving predictions to %s' % out_path)\n",
        "        out_file.write('id,category\\n')\n",
        "        idx = 0\n",
        "        for result in predictions:\n",
        "            count += 1\n",
        "            out_file.write(str(idx) + ',' + result + '\\n')\n",
        "            idx += 1\n",
        "            if count % 100 == 0:\n",
        "                print('Predicted %d sentences' % count)\n",
        "    out_file.close()\n",
        "    print('Finished predicting %d sentences' % count)\n",
        "    print('Results saved in %s' % Path(out_path).absolute())\n",
        "\n",
        "#definição do modelo utilizado\n",
        "def train_svm_model(train_df, dev_df):\n",
        "    processed_clf_svm = Pipeline([('vect', CountVectorizer(stop_words=stopwords)), ('tfidf', TfidfTransformer()),\n",
        "                                  ('clf-svm', SGDClassifier(loss='hinge', max_iter=2000, tol=1e-5, random_state=42))])\n",
        "    processed_clf_svm = processed_clf_svm.fit(train_df['text'], train_df['label'])\n",
        "    return processed_clf_svm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E3TrS8E-q3H",
        "colab_type": "code",
        "outputId": "171c5aa1-6463-40e4-dd72-220677f07113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "#download do dataset\n",
        "!wget https://github.com/jacksonsavitraz/kaggle-nlp-competition/raw/master/df.zip\n",
        "!unzip df.zip"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-17 13:20:34--  https://github.com/jacksonsavitraz/kaggle-nlp-competition/raw/master/df.zip\n",
            "Resolving github.com (github.com)... 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/jacksonsavitraz/kaggle-nlp-competition/master/df.zip [following]\n",
            "--2019-07-17 13:20:34--  https://raw.githubusercontent.com/jacksonsavitraz/kaggle-nlp-competition/master/df.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15145423 (14M) [application/zip]\n",
            "Saving to: ‘df.zip.1’\n",
            "\n",
            "\rdf.zip.1              0%[                    ]       0  --.-KB/s               \rdf.zip.1            100%[===================>]  14.44M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-07-17 13:20:35 (194 MB/s) - ‘df.zip.1’ saved [15145423/15145423]\n",
            "\n",
            "Archive:  df.zip\n",
            "replace df_train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: df_train.csv            \n",
            "  inflating: df_valid.csv            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZJO5Y73L4n-9",
        "colab_type": "code",
        "outputId": "d0673932-e06c-473c-846e-44d866c7ceae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "#carrega o dataset de treinamento\n",
        "train_df = load_dataset('df_train.csv', train=True)\n",
        "train_df.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Casa da Barra Funda tem clima roceiro e receit...</td>\n",
              "      <td>comida</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Professores de SP decidem manter greve; grupo ...</td>\n",
              "      <td>educacao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Em segunda edição, concurso paga R$ 35 mil par...</td>\n",
              "      <td>empreendedorsocial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Usar maconha por anos não faz tão mal para a s...</td>\n",
              "      <td>equilibrioesaude</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Baleia-azul percorre 5.200 km e revela a cient...</td>\n",
              "      <td>ciencia</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text               label\n",
              "0  Casa da Barra Funda tem clima roceiro e receit...              comida\n",
              "1  Professores de SP decidem manter greve; grupo ...            educacao\n",
              "2  Em segunda edição, concurso paga R$ 35 mil par...  empreendedorsocial\n",
              "3  Usar maconha por anos não faz tão mal para a s...    equilibrioesaude\n",
              "4  Baleia-azul percorre 5.200 km e revela a cient...             ciencia"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "a8Nx5YRd4n_L",
        "colab_type": "code",
        "outputId": "b4adca93-f417-4e32-f0ec-ff53952f5ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "#carrega o dataset de validação\n",
        "dev_df = load_dataset('df_valid.csv', train=False)\n",
        "dev_df.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Vitrine de Dilma, Pronatec terá orçamento 65% ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Por direitos autorais e publicidade, 'youtuber...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rótulos de alimentos terão que alertar sobre l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sociedade britânica de compositores processa S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Por Fies, aluna madruga na porta da FMU, mas s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  Vitrine de Dilma, Pronatec terá orçamento 65% ...\n",
              "1  Por direitos autorais e publicidade, 'youtuber...\n",
              "2  Rótulos de alimentos terão que alertar sobre l...\n",
              "3  Sociedade britânica de compositores processa S...\n",
              "4  Por Fies, aluna madruga na porta da FMU, mas s..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "V-vXiCR-4n_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#treina o modelo\n",
        "svm_model = train_svm_model(train_df, dev_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZkMqTFWBB8h",
        "colab_type": "code",
        "outputId": "71a7235c-3e07-4cb8-e7db-61d416342f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#faz a predição\n",
        "predicted_svm = svm_model.predict(train_df['text'])\n",
        "print(balanced_accuracy_score(train_df['label'], predicted_svm))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9943942884351809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4F78yJ2C3IK",
        "colab_type": "code",
        "outputId": "8263e0da-ee12-4d26-ad76-ada5d2ce4cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        }
      },
      "source": [
        "#salva o arquivo de submissão\n",
        "write_predictions(svm_model.predict(dev_df['text']), 'submission.csv')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving predictions to submission.csv\n",
            "Predicted 100 sentences\n",
            "Predicted 200 sentences\n",
            "Predicted 300 sentences\n",
            "Predicted 400 sentences\n",
            "Predicted 500 sentences\n",
            "Predicted 600 sentences\n",
            "Predicted 700 sentences\n",
            "Predicted 800 sentences\n",
            "Predicted 900 sentences\n",
            "Predicted 1000 sentences\n",
            "Predicted 1100 sentences\n",
            "Predicted 1200 sentences\n",
            "Predicted 1300 sentences\n",
            "Predicted 1400 sentences\n",
            "Predicted 1500 sentences\n",
            "Predicted 1600 sentences\n",
            "Predicted 1700 sentences\n",
            "Predicted 1800 sentences\n",
            "Predicted 1900 sentences\n",
            "Predicted 2000 sentences\n",
            "Predicted 2100 sentences\n",
            "Predicted 2200 sentences\n",
            "Predicted 2300 sentences\n",
            "Predicted 2400 sentences\n",
            "Predicted 2500 sentences\n",
            "Predicted 2600 sentences\n",
            "Predicted 2700 sentences\n",
            "Predicted 2800 sentences\n",
            "Predicted 2900 sentences\n",
            "Predicted 3000 sentences\n",
            "Predicted 3100 sentences\n",
            "Predicted 3200 sentences\n",
            "Predicted 3300 sentences\n",
            "Predicted 3400 sentences\n",
            "Predicted 3500 sentences\n",
            "Predicted 3600 sentences\n",
            "Predicted 3700 sentences\n",
            "Predicted 3800 sentences\n",
            "Predicted 3900 sentences\n",
            "Predicted 4000 sentences\n",
            "Predicted 4100 sentences\n",
            "Predicted 4200 sentences\n",
            "Finished predicting 4251 sentences\n",
            "Results saved in /content/submission.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euwyyUtdGLFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#baixa o arquivo para submissão no kaggle\n",
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}